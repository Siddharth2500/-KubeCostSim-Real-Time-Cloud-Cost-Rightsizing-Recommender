# -*- coding: utf-8 -*-
"""ðŸ’° KubeCostSim â€” Real-Time Cloud Cost & Rightsizing Recommender

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

# KubeCostSim: Real-Time Cloud Cost & Rightsizing Recommender
# -----------------------------------------------------------
# Colab-ready single cell. Dependencies: numpy, pandas, matplotlib (preinstalled in Colab)
# Produces:
#   - cost_samples.csv
#   - rightsizing.csv
#   - cost_timeseries.png
#   - requests_vs_usage.png
#
# Author: Siddharth Raut â€” DevOps & Cloud Engineer

import time
import math
import random
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Any, Optional
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# -----------------------------
# Configuration & Helpers
# -----------------------------
np.set_printoptions(suppress=True, precision=4)
random.seed(42)
np.random.seed(42)

def ts_now_str():
    return time.strftime("%H:%M:%S")

def clamp(x, lo, hi):
    return max(lo, min(hi, x))

# -----------------------------
# Price Model
# -----------------------------
@dataclass
class PriceModel:
    """Simple per-hour pricing (proxy values)"""
    price_cpu_per_hr: float = 0.031   # $ per vCPU-hour (example)
    price_mem_per_hr: float = 0.004   # $ per GB-hour  (example)

    def per_second(self, cpu_req: float, mem_req: float) -> float:
        return (cpu_req * self.price_cpu_per_hr + mem_req * self.price_mem_per_hr) / 3600.0

# -----------------------------
# Workload Simulation
# -----------------------------
@dataclass
class Workload:
    name: str
    cpu_req: float         # requested vCPU
    mem_req: float         # requested GB
    profile: str = "steady"  # steady | spiky | bursty
    region: str = "us-east-1"
    _cpu_used: float = 0.0
    _mem_used: float = 0.0

    def step(self):
        """
        Simulate resource usage based on profile.
        Keeps usage near a fraction of the request with randomness.
        """
        base_cpu_util = {"steady": 0.55, "spiky": 0.45, "bursty": 0.35}.get(self.profile, 0.5)
        base_mem_util = {"steady": 0.65, "spiky": 0.55, "bursty": 0.5}.get(self.profile, 0.6)

        # Add noise; spiky/bursty get higher variance
        cpu_sigma = {"steady": 0.12, "spiky": 0.22, "bursty": 0.35}[self.profile]
        mem_sigma = {"steady": 0.10, "spiky": 0.18, "bursty": 0.22}[self.profile]

        cpu_used = np.random.normal(self.cpu_req * base_cpu_util, self.cpu_req * cpu_sigma)
        mem_used = np.random.normal(self.mem_req * base_mem_util, self.mem_req * mem_sigma)

        # Occasionally spike for spiky/bursty
        if self.profile == "spiky" and random.random() < 0.08:
            cpu_used *= 1.8
        if self.profile == "bursty" and random.random() < 0.15:
            cpu_used *= 2.2
            mem_used *= 1.4

        # Clamp usage to non-negative and some sane upper bound (e.g., 2x request)
        self._cpu_used = max(0.02, min(self.cpu_req * 2.0, cpu_used))
        self._mem_used = max(0.05, min(self.mem_req * 2.0, mem_used))

        return self._cpu_used, self._mem_used

# -----------------------------
# Engine: Simulation + Costing + Rightsizing
# -----------------------------
@dataclass
class CostEngine:
    workloads: List[Workload]
    prices: PriceModel = field(default_factory=PriceModel)
    history: List[Dict[str, Any]] = field(default_factory=list)

    def tick(self):
        ts = ts_now_str()
        for w in self.workloads:
            cpu_used, mem_used = w.step()
            # Cost is charged on *requested* resources (typical k8s on-demand accounting proxy)
            cost_per_sec = self.prices.per_second(w.cpu_req, w.mem_req)
            self.history.append({
                "ts": ts,
                "workload": w.name,
                "cpu_req": round(w.cpu_req, 4),
                "cpu_used": round(cpu_used, 4),
                "mem_req": round(w.mem_req, 4),
                "mem_used": round(mem_used, 4),
                "cost_per_sec": float(cost_per_sec),
                "region": w.region,
                "profile": w.profile,
            })

    def simulate(self, duration: int = 60, interval: int = 1):
        """
        Run simulation for duration seconds, sampling every interval seconds.
        """
        steps = max(1, duration // interval)
        for _ in range(steps):
            self.tick()
            time.sleep(interval)

    def df(self) -> pd.DataFrame:
        return pd.DataFrame(self.history)

    # -------- Rightsizing ----------
    @staticmethod
    def _percentile(arr: np.ndarray, p: float) -> float:
        if len(arr) == 0:
            return 0.0
        return float(np.percentile(arr, p))

    def rightsizing(
        self,
        headroom: float = 1.2,
        min_cpu: float = 0.25,    # floor vCPU
        min_mem: float = 0.25,    # floor GB
        policy: str = "p90"       # "avg" | "p90" | "p95"
    ) -> pd.DataFrame:
        """
        Recommend CPU/Memory requests per workload using either mean or percentile policy.
        headroom is a multiplier (safety factor).
        """
        df = self.df()
        if df.empty:
            return pd.DataFrame()

        # Aggregate per workload
        grouped = df.groupby("workload")
        rows = []
        for wl, g in grouped:
            cpu_used = g["cpu_used"].values
            mem_used = g["mem_used"].values

            if policy == "avg":
                base_cpu = float(np.mean(cpu_used))
                base_mem = float(np.mean(mem_used))
            elif policy == "p95":
                base_cpu = self._percentile(cpu_used, 95)
                base_mem = self._percentile(mem_used, 95)
            else:  # default p90
                base_cpu = self._percentile(cpu_used, 90)
                base_mem = self._percentile(mem_used, 90)

            reco_cpu = max(min_cpu, base_cpu * headroom)
            reco_mem = max(min_mem, base_mem * headroom)

            # Current requests (take last known; all rows hold same reqs)
            cpu_req = float(g["cpu_req"].iloc[-1])
            mem_req = float(g["mem_req"].iloc[-1])

            # Savings estimate per hour if we reduce request (no negative savings)
            cpu_saving_vcpu = max(0.0, cpu_req - reco_cpu)
            mem_saving_gb = max(0.0, mem_req - reco_mem)
            savings_hr = cpu_saving_vcpu * self.prices.price_cpu_per_hr + \
                         mem_saving_gb * self.prices.price_mem_per_hr

            rows.append({
                "workload": wl,
                "policy": policy,
                "headroom": headroom,
                "cpu_req": round(cpu_req, 3),
                "cpu_reco": round(reco_cpu, 3),
                "cpu_saving_vcpu": round(cpu_saving_vcpu, 3),
                "mem_req": round(mem_req, 3),
                "mem_reco": round(reco_mem, 3),
                "mem_saving_gb": round(mem_saving_gb, 3),
                "estimated_savings_hr_$": round(savings_hr, 4),
                "cpu_used_avg": round(float(np.mean(cpu_used)), 3),
                "cpu_used_p90": round(self._percentile(cpu_used, 90), 3),
                "cpu_used_p95": round(self._percentile(cpu_used, 95), 3),
                "mem_used_avg": round(float(np.mean(mem_used)), 3),
                "mem_used_p90": round(self._percentile(mem_used, 90), 3),
                "mem_used_p95": round(self._percentile(mem_used, 95), 3),
            })

        rec = pd.DataFrame(rows).sort_values("estimated_savings_hr_$", ascending=False)
        return rec

    # --------- Plots ----------
    def plot_cost_timeseries(self, outfile: str = "cost_timeseries.png"):
        df = self.df()
        if df.empty:
            print("No data to plot.")
            return
        # cumulative cost proxy over time (sum of per-second costs per tick)
        per_ts = df.groupby("ts")["cost_per_sec"].sum().cumsum()
        plt.figure(figsize=(10, 5))
        plt.plot(per_ts.index, per_ts.values)
        plt.title("Cumulative Cost (proxy units)")
        plt.xlabel("Time (HH:MM:SS)")
        plt.ylabel("Cumulative Cost (sec-based proxy)")
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        plt.savefig(outfile, dpi=220)
        print(f"Saved â†’ {outfile}")

    def plot_requests_vs_usage(self, outfile: str = "requests_vs_usage.png"):
        df = self.df()
        if df.empty:
            print("No data to plot.")
            return
        agg = df.groupby("workload").agg(
            cpu_req=("cpu_req", "last"),
            mem_req=("mem_req", "last"),
            cpu_used_avg=("cpu_used", "mean"),
            mem_used_avg=("mem_used", "mean"),
            cpu_used_p95=("cpu_used", lambda x: np.percentile(x, 95)),
            mem_used_p95=("mem_used", lambda x: np.percentile(x, 95)),
        )
        # bar chart: request vs avg usage vs p95 usage
        ax = agg[["cpu_req", "cpu_used_avg", "cpu_used_p95"]].plot(kind="bar", figsize=(10,5))
        plt.title("CPU: Request vs Avg vs P95 (per workload)")
        plt.ylabel("vCPU")
        plt.tight_layout()
        plt.savefig("cpu_requests_usage.png", dpi=220)
        print("Saved â†’ cpu_requests_usage.png")

        ax = agg[["mem_req", "mem_used_avg", "mem_used_p95"]].plot(kind="bar", figsize=(10,5))
        plt.title("Memory: Request vs Avg vs P95 (per workload)")
        plt.ylabel("GB")
        plt.tight_layout()
        plt.savefig("mem_requests_usage.png", dpi=220)
        print("Saved â†’ mem_requests_usage.png")

        # combined thumbnail
        fig = plt.figure(figsize=(10,5))
        plt.suptitle("Requests vs Usage (CPU & Memory)")
        plt.tight_layout()
        plt.savefig(outfile, dpi=220)
        print(f"Saved â†’ {outfile}")

# -----------------------------
# Demo Run (adjust duration/interval as needed)
# -----------------------------
if __name__ == "__main__":
    workloads = [
        Workload("web-frontend", cpu_req=1.0, mem_req=1.0, profile="steady"),
        Workload("api",           cpu_req=1.5, mem_req=2.0, profile="spiky"),
        Workload("worker",        cpu_req=2.0, mem_req=2.5, profile="bursty"),
    ]
    engine = CostEngine(workloads)

    # Quick demo: ~20 seconds, 1-second sampling
    engine.simulate(duration=20, interval=1)

    # Show a small sample
    df = engine.df()
    print("=== Sample Metrics ===")
    print(df.tail(8).to_string(index=False))

    # Rightsizing with p90 + 20% headroom
    rec = engine.rightsizing(headroom=1.2, policy="p90")
    print("\n=== Rightsizing Recommendations (p90 + headroom=1.2) ===")
    print(rec.to_string(index=False))

    # Save artifacts
    df.to_csv("cost_samples.csv", index=False)
    rec.to_csv("rightsizing.csv", index=False)
    print("\nSaved â†’ cost_samples.csv, rightsizing.csv")

    # Plots
    engine.plot_cost_timeseries("cost_timeseries.png")
    engine.plot_requests_vs_usage("requests_vs_usage.png")